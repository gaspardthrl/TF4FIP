{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract names of images for Overleaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PNG files:\n",
      "Mean Precision Heatmap (Hours x Models) - night hours.png\n",
      "Mean Precision Heatmap (Models x Horizons).png\n",
      "Mean Precision Heatmap (Models x Horizons) - day hours only.png\n",
      "Mean Precision Heatmap (Hours x Models).png\n",
      "Mean Precision Heatmap (Days x Hours).png\n",
      "Mean Precision Heatmap (Models x Days) - night hours.png\n",
      "Mean Precision Heatmap (Days x Hours) - night hours.png\n",
      "Mean Precision Heatmap (Models x Horizons) - night hours.png\n",
      "Mean Precision Heatmap (Models x Days) - day hours.png\n",
      "Mean Precision Heatmap (Hours x Models) - day hours.png\n",
      "Mean Precision Heatmap (Models x Days).png\n",
      "Mean Precision Heatmap (Days x Hours) - day hours.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Set the path to the folder containing PNG files\n",
    "folder_path = '/path/to/your/folder'  # <-- Change this to your folder path\n",
    "\n",
    "# Use glob to find all .png files in the folder\n",
    "png_file_paths = glob.glob(os.path.join(\"./\", '*.png'))\n",
    "\n",
    "# Extract just the file names from the paths\n",
    "png_file_names = [os.path.basename(path) for path in png_file_paths]\n",
    "\n",
    "# Print the list of PNG file names\n",
    "print(\"Found PNG files:\")\n",
    "for name in png_file_names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests of Chronos (prediction of number of passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantiles:  tensor([[[432.9833, 451.0670, 475.7268],\n",
      "         [424.3524, 464.4244, 495.6600],\n",
      "         [451.8890, 483.9467, 516.6208],\n",
      "         [447.9846, 490.1116, 524.4297],\n",
      "         [494.8380, 538.4035, 573.7491],\n",
      "         [545.3904, 577.4480, 651.6326],\n",
      "         [589.1613, 648.3446, 707.5280],\n",
      "         [566.3511, 634.9873, 671.1549],\n",
      "         [462.1639, 549.7059, 576.4205],\n",
      "         [404.8301, 464.4244, 495.0435],\n",
      "         [355.0997, 423.3249, 480.2477],\n",
      "         [389.8288, 447.9846, 485.3852]]])\n",
      "Mean:  tensor([[452.6083, 460.8282, 483.4329, 488.8786, 532.2386, 595.8400, 654.4069,\n",
      "         620.6025, 528.1286, 457.5402, 424.4552, 445.0049]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # requires: pip install pandas\n",
    "import torch\n",
    "from chronos import BaseChronosPipeline\n",
    "\n",
    "pipeline = BaseChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-tiny\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
    "    device_map=\"cpu\",  # use \"cpu\" for CPU inference\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AileenNielsen/TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\"\n",
    ")\n",
    "\n",
    "# context must be either a 1D tensor, a list of 1D tensors,\n",
    "# or a left-padded 2D tensor with batch as the first dimension\n",
    "# quantiles is an fp32 tensor with shape [batch_size, prediction_length, num_quantile_levels]\n",
    "# mean is an fp32 tensor with shape [batch_size, prediction_length]\n",
    "quantiles, mean = pipeline.predict_quantiles(\n",
    "    context=torch.tensor(df[\"#Passengers\"]),\n",
    "    prediction_length=12,\n",
    "    quantile_levels=[0.1, 0.5, 0.9],\n",
    ")\n",
    "\n",
    "print(\"Quantiles: \", quantiles)\n",
    "print(\"Mean: \", mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Shape: torch.Size([2, 5])\n",
      "Quantiles:\n",
      " torch.Size([2, 3, 3])\n",
      "Mean:\n",
      " torch.Size([2, 3])\n",
      "Quantiles:\n",
      " tensor([[[128.1818, 142.0821, 154.8387],\n",
      "         [119.6481, 134.1642, 159.1496],\n",
      "         [111.6422, 131.5249, 148.5924]],\n",
      "\n",
      "        [[232.0968, 251.6129, 280.9677],\n",
      "         [229.6774, 254.8387, 283.8710],\n",
      "         [234.6774, 252.4193, 280.8064]]])\n",
      "Mean:\n",
      " tensor([[142.3460, 136.8915, 134.0323],\n",
      "        [252.9032, 256.2097, 257.7419]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from chronos import ChronosPipeline\n",
    "\n",
    "# Load the Chronos-T5 model\n",
    "pipeline = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-small\",  # Use \"amazon/chronos-bolt-small\" for the Bolt model\n",
    "    device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Simulating two time series (batch_size=2)\n",
    "context = torch.tensor([\n",
    "    [100, 110, 120, 130, 140],  # First time series (e.g., Store A sales)\n",
    "    [200, 210, 220, 230, 240]   # Second time series (e.g., Store B sales)\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Define prediction parameters\n",
    "prediction_length = 3  # Forecast next 3 time steps\n",
    "quantile_levels = [0.1, 0.5, 0.9]  # Lower, median, upper quantiles\n",
    "\n",
    "# Ensure the context is correctly shaped as [batch_size, sequence_length]\n",
    "print(\"Context Shape:\", context.shape)  # Should be (2, 5)\n",
    "\n",
    "\n",
    "# quantiles is an fp32 tensor with shape [batch_size, prediction_length, num_quantile_levels]\n",
    "# mean is an fp32 tensor with shape [batch_size, prediction_length]\n",
    "quantiles, mean = pipeline.predict_quantiles(\n",
    "    context=context, \n",
    "    prediction_length=prediction_length, \n",
    "    quantile_levels=quantile_levels\n",
    ")\n",
    "\n",
    "# Print output\n",
    "print(\"Quantiles:\\n\", quantiles.shape)\n",
    "print(\"Mean:\\n\", mean.shape)\n",
    "\n",
    "print(\"Quantiles:\\n\", quantiles)\n",
    "print(\"Mean:\\n\", mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Chronos with our data (ES=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def fetch(ticker='ES=F', interval=\"1h\", session_start=None, session_end=None, tz=\"America/Chicago\"):\n",
    "    data = yf.download(tickers=ticker, interval=interval, start=session_start, end=session_end, prepost=False)\n",
    "\n",
    "    # Set the correct timezone and account for daylight saving hours\n",
    "    if interval[-1] in [\"m\", \"h\"]:\n",
    "      data.index = data.index.tz_convert(tz)\n",
    "    # Reset index to get a clean DataFrame\n",
    "    data.reset_index(inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>ES=F</th>\n",
       "      <th>ES=F</th>\n",
       "      <th>ES=F</th>\n",
       "      <th>ES=F</th>\n",
       "      <th>ES=F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-13 17:00:00-06:00</td>\n",
       "      <td>4148.25</td>\n",
       "      <td>4149.75</td>\n",
       "      <td>4147.25</td>\n",
       "      <td>4149.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-13 18:00:00-06:00</td>\n",
       "      <td>4145.50</td>\n",
       "      <td>4148.25</td>\n",
       "      <td>4143.00</td>\n",
       "      <td>4148.25</td>\n",
       "      <td>6771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-13 19:00:00-06:00</td>\n",
       "      <td>4143.75</td>\n",
       "      <td>4147.50</td>\n",
       "      <td>4142.00</td>\n",
       "      <td>4145.50</td>\n",
       "      <td>6220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-13 20:00:00-06:00</td>\n",
       "      <td>4142.00</td>\n",
       "      <td>4144.50</td>\n",
       "      <td>4140.75</td>\n",
       "      <td>4143.75</td>\n",
       "      <td>4607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-13 21:00:00-06:00</td>\n",
       "      <td>4143.25</td>\n",
       "      <td>4144.00</td>\n",
       "      <td>4140.25</td>\n",
       "      <td>4142.25</td>\n",
       "      <td>4167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10536</th>\n",
       "      <td>2024-12-13 11:00:00-06:00</td>\n",
       "      <td>6042.25</td>\n",
       "      <td>6053.25</td>\n",
       "      <td>6041.50</td>\n",
       "      <td>6051.25</td>\n",
       "      <td>188169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10537</th>\n",
       "      <td>2024-12-13 12:00:00-06:00</td>\n",
       "      <td>6054.50</td>\n",
       "      <td>6057.50</td>\n",
       "      <td>6041.25</td>\n",
       "      <td>6042.25</td>\n",
       "      <td>165926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10538</th>\n",
       "      <td>2024-12-13 13:00:00-06:00</td>\n",
       "      <td>6056.50</td>\n",
       "      <td>6059.75</td>\n",
       "      <td>6052.50</td>\n",
       "      <td>6054.50</td>\n",
       "      <td>125419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10539</th>\n",
       "      <td>2024-12-13 14:00:00-06:00</td>\n",
       "      <td>6055.75</td>\n",
       "      <td>6060.25</td>\n",
       "      <td>6050.75</td>\n",
       "      <td>6056.50</td>\n",
       "      <td>253171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10540</th>\n",
       "      <td>2024-12-13 15:00:00-06:00</td>\n",
       "      <td>6051.25</td>\n",
       "      <td>6056.00</td>\n",
       "      <td>6047.00</td>\n",
       "      <td>6055.75</td>\n",
       "      <td>62576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10541 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price                   Datetime    Close     High      Low     Open  Volume\n",
       "Ticker                               ES=F     ES=F     ES=F     ES=F    ES=F\n",
       "0      2023-02-13 17:00:00-06:00  4148.25  4149.75  4147.25  4149.75       0\n",
       "1      2023-02-13 18:00:00-06:00  4145.50  4148.25  4143.00  4148.25    6771\n",
       "2      2023-02-13 19:00:00-06:00  4143.75  4147.50  4142.00  4145.50    6220\n",
       "3      2023-02-13 20:00:00-06:00  4142.00  4144.50  4140.75  4143.75    4607\n",
       "4      2023-02-13 21:00:00-06:00  4143.25  4144.00  4140.25  4142.25    4167\n",
       "...                          ...      ...      ...      ...      ...     ...\n",
       "10536  2024-12-13 11:00:00-06:00  6042.25  6053.25  6041.50  6051.25  188169\n",
       "10537  2024-12-13 12:00:00-06:00  6054.50  6057.50  6041.25  6042.25  165926\n",
       "10538  2024-12-13 13:00:00-06:00  6056.50  6059.75  6052.50  6054.50  125419\n",
       "10539  2024-12-13 14:00:00-06:00  6055.75  6060.25  6050.75  6056.50  253171\n",
       "10540  2024-12-13 15:00:00-06:00  6051.25  6056.00  6047.00  6055.75   62576\n",
       "\n",
       "[10541 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(ticker=\"ES=F\", interval=\"1h\", session_start = pd.Timestamp('2023-02-13 17:00', tz=\"America/Chicago\"), session_end = pd.Timestamp('2024-12-13 16:00', tz=\"America/Chicago\"), tz=\"America/Chicago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "def wavelet_denoise(df, wavelet='db1', level=1):\n",
    "    \"\"\"\n",
    "    Apply wavelet denoising to all numeric columns of a Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Pandas DataFrame to denoise\n",
    "    - wavelet: Type of wavelet to use (default is 'db1')\n",
    "    - level: Level of decomposition for wavelet transform\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with denoised data.\n",
    "    \"\"\"\n",
    "    def denoise_column(column):\n",
    "        # Perform wavelet decomposition\n",
    "        coeffs = pywt.wavedec(column, wavelet, level=level)\n",
    "        # Apply thresholding to detail coefficients\n",
    "        sigma = np.median(np.abs(coeffs[-level])) / 0.6745  # Estimate noise sigma\n",
    "        threshold = sigma * np.sqrt(2 * np.log(len(column)))\n",
    "        denoised_coeffs = [pywt.threshold(c, threshold) if i > 0 else c for i, c in enumerate(coeffs)]\n",
    "        # Reconstruct the signal\n",
    "        return pywt.waverec(denoised_coeffs, wavelet)[:len(column)]\n",
    "\n",
    "    # Apply denoising to each numeric column\n",
    "    denoised_data = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        denoised_data[col] = denoise_column(df[col].values)\n",
    "\n",
    "    # Add the denoised data to a new DataFrame\n",
    "    denoised_df = df.copy()\n",
    "    for col, denoised_col in denoised_data.items():\n",
    "        denoised_df[col] = denoised_col\n",
    "\n",
    "    return denoised_df\n",
    "\n",
    "def preprocess(df, dfDaily=None):\n",
    "  # Remove the ticker index\n",
    "  df.columns = df.columns.droplevel(\"Ticker\")\n",
    "\n",
    "  df.columns.names = [None]\n",
    "\n",
    "  # set the index of the dataframe to the datetime column. Meaning, the datetime is not a column anymore and the data is ordered by row, where each row is a datetime\n",
    "  df.set_index(\"Datetime\", inplace=True)\n",
    "  df.index = pd.to_datetime(df.index)\n",
    "\n",
    "  # Fill frequency and fill the gaps between 4PM-5PM (the market closes at 4PM and opens at 5PM)\n",
    "  df = df.asfreq('h') # if the dataframe had a 2h interval it will expand it to 1h interval by adding NaN values\n",
    "  df = df.interpolate(method=\"time\") # fill the eventual NaN values with the time interpolation method\n",
    "\n",
    "  # Add week of year\n",
    "  df[\"Week\"] = df.index.isocalendar().week\n",
    "\n",
    "  # Add day of week\n",
    "  df[\"Day\"] = df.index.dayofweek\n",
    "\n",
    "  # Add hour\n",
    "  df[\"Hour\"] = df.index.hour\n",
    "\n",
    "\n",
    "  def emroc(df, column, span, lag):\n",
    "    \"\"\"\n",
    "    Rate of Change (ROC) calculation and Exponential Moving Average (EMA) smoothing.\n",
    "\n",
    "    EWMA smooths the ROC using exponential weighting, where recent values have more weight.\n",
    "    The span controls how much past data influences the smoothed value.\n",
    "\n",
    "    \"\"\"\n",
    "    df[f\"ROC_{column}\"] = df[column].pct_change(lag)\n",
    "    df[f\"EMROC_{column}\"] = df[f\"ROC_{column}\"].ewm(span=span, adjust=False).mean()\n",
    "    return df\n",
    "\n",
    "  def atr(df, span, lag):\n",
    "    df['Prev Close'] = df['Close'].shift(lag) # get the previous close price\n",
    "    high_low = df['High'] - df['Low']\n",
    "    high_prev_close = (df['High'] - df['Prev Close']).abs()\n",
    "    low_prev_close = (df['Low'] - df['Prev Close']).abs()\n",
    "    df['True Range'] = high_low.combine(high_prev_close, max).combine(low_prev_close, max)\n",
    "    df[f'ATR_{span}'] = df['True Range'].rolling(window=span).mean()\n",
    "    df[f'ATR_{span}'] = df[f'ATR_{span}'] / df['Close']\n",
    "    return df\n",
    "\n",
    "  def rsi(df, column, span, lag):\n",
    "      df['Price Change'] = df['Close'].diff()\n",
    "      df['Gain'] = df['Price Change'].apply(lambda x: x if x > 0 else 0)\n",
    "      df['Loss'] = df['Price Change'].apply(lambda x: -x if x < 0 else 0)\n",
    "      df['Avg Gain'] = df['Gain'].rolling(window=span, min_periods=lag).mean()\n",
    "      df['Avg Loss'] = df['Loss'].rolling(window=span, min_periods=lag).mean()\n",
    "\n",
    "      # Calculate the RS (Relative Strength)\n",
    "      df['RS'] = df['Avg Gain'] / df['Avg Loss']\n",
    "\n",
    "      # Calculate the RSI\n",
    "      df['RSI'] = 100 - (100 / (1 + df['RS']))\n",
    "      return df\n",
    "\n",
    "  def distancesToMM(df, column, spans):\n",
    "    for span in spans:\n",
    "        df[f'MM_{span}'] = df['Close'].rolling(window=span).mean()\n",
    "        df[f'DistanceToMM{span}'] = ((df[\"Close\"] - df[f'MM_{span}']) / df[f'MM_{span}']) * 100\n",
    "    return df\n",
    "\n",
    "  def distancesToEMM(df, column, spans):\n",
    "      for span in spans:\n",
    "          df[f'EMM_{span}'] = df['Close'].ewm(span=span, adjust=False).mean()\n",
    "          df[f'DistanceToEMM{span}'] = ((df[\"Close\"] - df[f'EMM_{span}']) / df[f'EMM_{span}']) * 100\n",
    "      return df\n",
    "\n",
    "  df = emroc(df, \"Close\", 72, 2)\n",
    "  df = emroc(df, \"Volume\", 72, 2)\n",
    "\n",
    "  if dfDaily is not None:\n",
    "    dfDaily.columns = dfDaily.columns.droplevel(\"Ticker\")\n",
    "    dfDaily.columns.names = [None]\n",
    "    dfDaily[\"Datetime\"] = pd.to_datetime(dfDaily[\"Date\"]).dt.normalize()\n",
    "    dfDaily.drop([\"Date\"], axis=1, inplace=True)\n",
    "    dfDaily.set_index(\"Datetime\", inplace=True)\n",
    "\n",
    "    dfDaily = dfDaily.asfreq('D')\n",
    "    dfDaily = dfDaily.interpolate(method=\"time\")\n",
    "\n",
    "    dfDaily = atr(dfDaily, \"Close\", 10, 1)\n",
    "    dfDaily = rsi(dfDaily, \"Close\", 14, 1)\n",
    "\n",
    "    dfDaily = distancesToMM(dfDaily, \"Close\", [20, 60])\n",
    "    dfDaily = distancesToEMM(dfDaily, \"Close\", [20, 60])\n",
    "\n",
    "    row_idx = 0\n",
    "    rowDaily_idx = 0\n",
    "\n",
    "    df[\"ATR_10\"] = None\n",
    "    df[\"MM_20\"] = None\n",
    "    df[\"MM_60\"] = None\n",
    "    df[\"EMM_20\"] = None\n",
    "    df[\"EMM_60\"] = None\n",
    "    df[\"RSI\"] = None\n",
    "\n",
    "    step = len(df) / 100\n",
    "    curr = 1\n",
    "    import sys\n",
    "    import time\n",
    "\n",
    "    def progress_bar(completion, total):\n",
    "        # Calculate percentage\n",
    "        percent = (completion / total) * 100\n",
    "        # Create progress bar with stars based on the percentage\n",
    "        bar = '*' * int(percent // 2)  # The bar will have half as many stars as percentage\n",
    "        # Pad with spaces to make it 50 characters long\n",
    "        bar = bar.ljust(50, ' ')\n",
    "        # Print progress bar\n",
    "        if completion == total:\n",
    "            sys.stdout.write(f\"\\r[{bar}] 1 of 1 completed\\n\")\n",
    "        else:\n",
    "            sys.stdout.write(f\"\\r[{bar}] {percent:.0f}%\")\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    while row_idx < len(df):\n",
    "        if row_idx >= curr * step:\n",
    "            progress_bar(curr, 100)\n",
    "            curr += 1\n",
    "\n",
    "        if (df.index[row_idx].dayofweek == dfDaily.index[rowDaily_idx].dayofweek and df.index[row_idx].hour >= 17) or ((df.index[row_idx].dayofweek-1)%7 == dfDaily.index[rowDaily_idx].dayofweek and df.index[row_idx].hour < 17):\n",
    "            # Set values for columns VolumeDiff, CloseDiff, ATR10, MM20, MM60 using .loc\n",
    "            df.loc[df.index[row_idx], \"ATR_10\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"ATR_10\"]\n",
    "            df.loc[df.index[row_idx], \"MM_20\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"MM_20\"]\n",
    "            df.loc[df.index[row_idx], \"MM_60\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"MM_60\"]\n",
    "            df.loc[df.index[row_idx], \"EMM_20\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"EMM_20\"]\n",
    "            df.loc[df.index[row_idx], \"EMM_60\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"EMM_60\"]\n",
    "            df.loc[df.index[row_idx], \"RSI\"] = dfDaily.loc[dfDaily.index[rowDaily_idx], \"RSI\"]\n",
    "\n",
    "            row_idx += 1\n",
    "        else:\n",
    "            rowDaily_idx += 1\n",
    "    progress_bar(curr, 100)\n",
    "    df[\"DistanceToMM20\"] = ((df[\"Close\"] - df[\"MM_20\"]) / df[\"MM_20\"]) * 100\n",
    "    df[\"DistanceToMM60\"] = ((df[\"Close\"] - df[\"MM_60\"]) / df[\"MM_60\"]) * 100\n",
    "    df[\"DistanceToEMM20\"] = ((df[\"Close\"] - df[\"EMM_20\"]) / df[\"EMM_20\"]) * 100\n",
    "    df[\"DistanceToEMM60\"] = ((df[\"Close\"] - df[\"EMM_60\"]) / df[\"EMM_60\"]) * 100\n",
    "\n",
    "    df[\"Close_denoised\"] = wavelet_denoise(df.copy())[\"Close\"]\n",
    "    print(df.isna().sum())\n",
    "    df = df.tail(-max(df.isna().sum()))\n",
    "    return df\n",
    "  else:\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'Close', 'Volume', 'Week', 'Day', 'Hour', 'ROC_Close',\n",
       "       'EMROC_Close', 'ROC_Volume', 'EMROC_Volume', 'ATR_10', 'MM_20', 'MM_60',\n",
       "       'EMM_20', 'EMM_60', 'RSI', 'DistanceToMM20', 'DistanceToMM60',\n",
       "       'DistanceToEMM20', 'DistanceToEMM60', 'Close_denoised',\n",
       "       'Close_denoised_normalized', 'Hour_sin', 'Hour_cos', 'Day_sin',\n",
       "       'Day_cos', 'Week_sin', 'Week_cos', 'Close_denoised_standardized',\n",
       "       'score', 'APE', 'SIGN', 'Result', 'MATRIX_1', 'MATRIX_2', 'MATRIX_3',\n",
       "       'MATRIX_4', 'MATRIX_5', 'MATRIX_6', 'MATRIX_7', 'MATRIX_8', 'MATRIX_9',\n",
       "       'MATRIX_10', 'MATRIX_11', 'MATRIX_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "panda = pd.read_csv(\"es_future_final_chronos.csv\")\n",
    "panda.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
